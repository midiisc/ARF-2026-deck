<svg width="1800" height="1000" xmlns="http://www.w3.org/2000/svg" font-family="Segoe UI, Calibri, sans-serif">
  
  <defs>
    <style>
      .title { font-size: 36px; font-weight: bold; fill: white; text-anchor: start; }
      .subtitle { font-size: 22px; font-weight: bold; fill: #66ffaa; text-anchor: start; } /* Light Green/Teal */
      .term { font-size: 15px; font-weight: bold; fill: white; }
      .desc { font-size: 15px; fill: #e0e0e0; }
    </style>
  </defs>

  <rect width="100%" height="100%" fill="#0E1A2B" />
  
  <text x="50" y="80" class="title">Acronyms & Key Concepts (1/2): Acronyms (A-M)</text>
  <line x1="50" y1="100" x2="1750" y2="100" stroke="#3B8A8A" stroke-width="3" />

  <svg x="50" y="150" width="825" height="800">
    <text x="0" y="30" class="subtitle">Acronyms (A-F)</text>
    <text x="0" y="80" class="body">
      <tspan x="0" dy="0" class="term">API (Application Programming Interface)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A software interface that allows the VLA to programmatically query the KB.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">CLIP (Contrastive Language-Image Pre-Training)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A model from OpenAI that understands the relationship between images and text, used for affordance extraction.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">CoRL (Conference on Robot Learning)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: An annual international conference on robotics and machine learning (a publication target).</tspan>
      
      <tspan x="0" dy="2.2em" class="term">CoT (Chain-of-Thought)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: An explicit, step-by-step reasoning trace (e.g., "1. See cup...") generated by a model before it acts.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">DETR (DEtection TRansformer)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A SOTA vision model from Meta AI that uses transformers for object detection.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">DROID (Distributed Robot Interaction Dataset)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A large-scale, in-the-wild robot manipulation dataset used for training our VLA.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">ERQA (Embodied Reasoning and Question Answering)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A benchmark for testing a model's complex, context-aware spatial reasoning.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">FAISS (Facebook AI Similarity Search)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A Meta AI library for efficient semantic vector search (e.g., "find objects visually similar to this one").</tspan>
      
      <tspan x="0" dy="2.2em" class="term">FRO (Future Robotics Office)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A key strategic partner and stakeholder for this project at Samsung.</tspan>
    </text>
  </svg>
  
  <svg x="925" y="150" width="825" height="800">
    <text x="0" y="30" class="subtitle">Acronyms (G-M)</text>
    <text x="0" y="80" class="body">
      <tspan x="0" dy="0" class="term">GLIP (Grounded Language-Image Pre-Training)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A SOTA model that unifies object detection and phrase grounding, used for affordance extraction.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">GNN (Graph Neural Network)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A neural network architecture designed to learn directly from graph data (like our Neo4j KB).</tspan>
      
      <tspan x="0" dy="2.2em" class="term">GRC (Global Research Center)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: The Samsung research organization executing this project.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">HIL SERL (Human-in-the-Loop Sample-Efficient Reinforcement Learning)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: An active GRC project for training robots with less data, which we will leverage.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">ICRA (International Conference on Robotics and Automation)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: The flagship annual conference of the IEEE Robotics and Automation Society (a publication target).</tspan>
      
      <tspan x="0" dy="2.2em" class="term">IPC (Association Connecting Electronics Industries)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: (Formerly Institute for Printed Circuits) A global standards body. We use `IPC-A-610` as KB rules.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">KB (Knowledge Base)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A structured database storing facts, semantic relations, and physical constraints.</tspan>
      
      <tspan x="0" dy="2.2em" class="term">KPI (Key Performance Indicator)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A measurable value to gauge project success (e.g., Task Success Rate).</tspan>
      
      <tspan x="0" dy="2.2em" class="term">LLM (Large Language Model)</tspan>
      <tspan x="30" dy="1.3em" class="desc">• Definition: A foundational AI model (e.g., GPT, Gemini) used for CoT reasoning and extracting knowledge.</tspan>
    </text>
  </svg>
  
</svg>
